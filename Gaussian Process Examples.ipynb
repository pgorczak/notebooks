{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_samples(t, Zs, wrap, size=1.5):\n",
    "    \"\"\" Plot a number of processes in a grid.\n",
    "    \n",
    "    Args:\n",
    "        t: index array of size n\n",
    "        Zs: mxn array of m process samples\n",
    "        wrap: start a new line after this number of plots\n",
    "        size: size of each plot\n",
    "    \"\"\"\n",
    "    n_samples = Zs.shape[0]\n",
    "    df = pd.DataFrame(dict(\n",
    "        sample=np.repeat(range(n_samples), len(t)),\n",
    "        t=np.tile(t, n_samples),\n",
    "        Z=Zs.ravel()))\n",
    "    grid = sns.FacetGrid(df, col='sample', hue='sample', col_wrap=wrap, size=size)\n",
    "    grid.map(plt.plot, 't', 'Z', marker=\"o\", ms=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process\n",
    "\n",
    "GPs are a nice tool for probabilistic regression.\n",
    "\n",
    "## Links\n",
    "- [mathematicalmonk on YouTube](https://www.youtube.com/watch?v=vU6AiEYED9E&list=PLD0F06AA0D2E8FFBA&index=150)\n",
    "- **TODO** Nando de Freitas on YouTube\n",
    "\n",
    "## Context and definitions\n",
    "A random process (aka stochastic process) is a collection of random variables (outputs). In a GP, $n$ elements from some index set $S$ are mapped to random variables $Z_t: t \\in S$, and $(Z_{t1}, ..., Z_{tn})$ form a multivariate Gaussian distribution.\n",
    "\n",
    "### Intuition\n",
    "Often, the index set $S$ contains points in time. Now all *outputs*—let's call them *states*—associated with a point in time $Z_t$ form a multivariate Gaussian distribution. This means that each *state at some time* of the GP is another *dimension* of the overall Gaussian. The key point of GP is, that an **entire family of $S$ to output mappings** is **described by the characteristics** of this overall distribution. It has some mean $\\mu$ and—more importantly—a covariance $C$. The **covariance links** an **output** $Z_i$ to **all other outputs** (in general both past and future).\n",
    "\n",
    "### Example: random lines\n",
    "Let's pick some random slope $m \\sim \\mathcal{N}(0, 1)$ (Gaussian with mean 0 and variance 1). Our index can be any real number, so $S = \\mathbb{R}$. If we set our outputs to be\n",
    "\n",
    "$$\n",
    "Z_t = mt\n",
    "$$\n",
    "\n",
    "we get an overall Gaussian (by the affine property)\n",
    "\n",
    "$$\n",
    "(Z_{t0}, Z_{t1}, ...)^T = (t_0, t_1, ...)^T \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "Let's plot some samples from this process the straightforward way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_random_lines():\n",
    "    ms = np.random.randn(8)\n",
    "    t = np.linspace(0, 1, 5)\n",
    "    # Shortcut for computing m*t for each m and t\n",
    "    lines = np.outer(ms, t)\n",
    "    plot_samples(t, lines, 4)\n",
    "    \n",
    "plot_random_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and covariance\n",
    "Remember the key point: *we can express a process like random lines by the $\\mu$ and $C$ of a Gaussian distribution*. In general, we let $\\mu$ be a function $\\mu: S \\to \\mathbb{R}$. The covariance matrix $C$ is defined by another function $k: S \\times S \\to \\mathbb{R}$, such that $C_{ij} = k(t_i, t_j)$. With this, we have defined our overall Gaussian. Note that the covariance of two outputs is defined by a function on their indices: $\\mathrm{Cov}(Z_i, Z_j) = k(t_i, t_j)$.\n",
    "\n",
    "### Random lines revisited\n",
    "We can re-formulate the random lines process. Its mean function is zero and its covariance function is $k(t_i, t_j) = t_i t_j$. Let's draw some samples from that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ignore the warning, it's due to numerical precision errors.\n",
    "# You can modify the function to verify that all eigenvalues\n",
    "# of C are non-negative or very close to zero.\n",
    "\n",
    "def plot_random_lines_2():\n",
    "    # Define input set\n",
    "    t = np.linspace(0, 1, 5)\n",
    "    # Calculate mu and C\n",
    "    mu = np.zeros(5)\n",
    "    C = np.array([[i * j for j in t] for i in t])\n",
    "    # Draw samples\n",
    "    lines = np.random.multivariate_normal(mu, C, 8)\n",
    "    plot_samples(t, lines, 4)\n",
    "    \n",
    "    \n",
    "plot_random_lines_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To be continued...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
