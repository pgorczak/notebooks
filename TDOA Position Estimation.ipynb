{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position estimation from TDOA measurements\n",
    "\n",
    "**Note: everything is scaled by $c = 3 \\times 10^8$ (or we assume $c$ to be $1 \\frac{m}{s}$)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sensors = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.5, 0.0],\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 0.5],\n",
    "    [1.0, 0.5],\n",
    "    [0.0, 1.0],\n",
    "    [0.5, 1.0],\n",
    "    [1.0, 1.0]])\n",
    "\n",
    "n_sensors = sensors.shape[0]\n",
    "\n",
    "sns.set_style('ticks')\n",
    "plt.scatter(sensors[:, 0], sensors[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def toas(p):\n",
    "    \"\"\"Times of arrival at each sensor given position.\"\"\"\n",
    "    deltas = p[None, :] - sensors\n",
    "    distances = np.linalg.norm(deltas, axis=1)\n",
    "    return distances # recall c = 1\n",
    "\n",
    "\n",
    "def d_toas(p):\n",
    "    \"\"\"Jacobian of toa by position.\"\"\"\n",
    "    deltas = p[None, :] - sensors\n",
    "    distances = np.linalg.norm(deltas, axis=1)\n",
    "    return deltas / distances[:, None]\n",
    "\n",
    "\n",
    "def combinations(x):\n",
    "    \"\"\"Generate combinations for TDOA.\"\"\"\n",
    "    # Use first sensor as reference\n",
    "    return itertools.product([x[0]], x[1:])\n",
    "\n",
    "\n",
    "def differences(x):\n",
    "    \"\"\"Pairwise difference of combinations.\"\"\"\n",
    "    return np.array([t1 - t2 for t1, t2 in combinations(x)])\n",
    "\n",
    "\n",
    "def covariance_matrix(variance):\n",
    "    \"\"\"Combination-difference covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        variance: vector of variances of independent normally distributed random variables.\n",
    "    \n",
    "    Returns:\n",
    "        covariance matrix of applying differences() to the n.d.r. variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_covariance(comb1, comb2):\n",
    "        c = 0\n",
    "        for i in (comb1 & comb2):\n",
    "            c += variance[i]\n",
    "        return c\n",
    "    \n",
    "    sensor_combs = [set(sensors) for sensors in combinations(range(n_sensors))]\n",
    "    n_combs = len(sensor_combs)\n",
    "    sensor_comb_combs = itertools.product(sensor_combs, sensor_combs)\n",
    "    covariances = (get_covariance(c1, c2) for c1, c2 in sensor_comb_combs)\n",
    "    return np.fromiter(covariances, dtype=np.float).reshape((n_combs, n_combs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Kalman filter setup\n",
    "\n",
    "No system model; we assume that we get noisy measurements of one constant position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(p):\n",
    "    \"\"\"Predict TDOAs based on position.\"\"\"\n",
    "    return differences(toas(p))\n",
    "    \n",
    "\n",
    "def d_predict(p):\n",
    "    \"\"\"Jacobian of predict().\"\"\"\n",
    "    return differences(d_toas(p))\n",
    "\n",
    "\n",
    "def measure(truth, variance=np.ones(n_sensors)):\n",
    "    \"\"\"Noisy measurement given TOA variance for each sensor.\"\"\"\n",
    "    return differences(toas(truth) + np.random.randn(n_sensors) * variance)\n",
    "\n",
    "\n",
    "def measure_cov(variance=np.ones(n_sensors)):\n",
    "    \"\"\"Measurement covariance matrix.\"\"\"\n",
    "    return covariance_matrix(variance)\n",
    "\n",
    "\n",
    "def ekf_update(mean, cov, measure, measure_cov):\n",
    "    z = measure\n",
    "    R = measure_cov\n",
    "    y = predict(mean)\n",
    "    J = d_predict(mean)\n",
    "    \n",
    "    gain = cov.dot(J.T).dot(np.linalg.inv(J.dot(cov).dot(J.T) + R))\n",
    "    \n",
    "    return mean + gain.dot(z - y), (np.eye(len(mean)) - gain.dot(J)).dot(cov)\n",
    "\n",
    "\n",
    "def estimate(init_mean, init_cov, truth, measure_covariance, iterations, seed):\n",
    "    np.random.seed(seed)\n",
    "    R = np.copy(measure_covariance)\n",
    "    m = np.copy(init_mean)\n",
    "    c = np.copy(init_cov)\n",
    "    for _ in range(iterations):\n",
    "        m, c = ekf_update(m, c, measure(truth), R)\n",
    "        yield m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "Let's set up some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truth = np.array([0.5, 0.7])\n",
    "init_mean = np.array([0.3, 0.2])\n",
    "init_cov = np.eye(2) * 5\n",
    "iterations = 400\n",
    "np.random.seed(1234)\n",
    "variance = 5 * np.random.rand(n_sensors)\n",
    "measure_cov = covariance_matrix(variance)\n",
    "\n",
    "def error(estimates):\n",
    "    for mean, _ in estimates:\n",
    "        yield np.linalg.norm(mean - truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview\n",
    "\n",
    "Preview some estimation processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "for seed in [0, 100, 200, 300, 400]:\n",
    "    plt.plot(\n",
    "        range(iterations),\n",
    "        list(error(estimate(init_mean, init_cov, truth, measure_cov, iterations, seed))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "Compare with estimator that doesn't consider the TDOA-covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_with_covariance(seed):\n",
    "    return error(estimate(init_mean, init_cov, truth, measure_cov, iterations, seed))\n",
    "\n",
    "\n",
    "def error_variance_only(seed):\n",
    "    measure_cov = np.diag([v1 + v2 for v1, v2 in combinations(variance)])\n",
    "    return error(estimate(init_mean, init_cov, truth, measure_cov, iterations, seed))\n",
    "\n",
    "\n",
    "plt.plot(range(iterations), list(error_with_covariance(123)), label='with covariance')\n",
    "plt.plot(range(iterations), list(error_variance_only(123)), label='variance only')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_convergence():\n",
    "\n",
    "    def generate():\n",
    "        seeds = range(100)\n",
    "        for s in seeds:\n",
    "            for t, e in enumerate(error_with_covariance(s)):\n",
    "                yield t, s, 'with covariance', e\n",
    "            for t, e in enumerate(error_variance_only(s)):\n",
    "                yield t, s, 'variance only', e\n",
    "            \n",
    "    times = deque()\n",
    "    units = deque()\n",
    "    conditions = deque()\n",
    "    values = deque()\n",
    "\n",
    "    for t, u, c, v in generate():\n",
    "        times.append(t)\n",
    "        units.append(u)\n",
    "        conditions.append(c)\n",
    "        values.append(v)\n",
    "        \n",
    "    df = pd.DataFrame(dict(iteration=times, seed=units, method=conditions, error=values))\n",
    "\n",
    "    sns.tsplot(data=df, time=\"iteration\", unit=\"seed\",\n",
    "               condition=\"method\", value=\"error\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_final_error():\n",
    "    \n",
    "    def last(iterator):\n",
    "        return deque(iterator, maxlen=1)[0]\n",
    "    \n",
    "    plt.scatter(\n",
    "        range(100),\n",
    "        list(last(error_with_covariance(s)) for s in range(100)),\n",
    "        label='final error with covariance')\n",
    "    plt.scatter(\n",
    "        range(100),\n",
    "        list(last(error_variance_only(s)) for s in range(100)),\n",
    "        label='final error variance only')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_final_error()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
